{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4fb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e96593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unscaled traces shape:  (500, 5000)\n",
      "scaled traces shape:  (500, 5000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "type_converter = {i: lambda x: int(x, 16) for i in range(16)}\n",
    "LAB_PATH = \"/home/raghul/Documents/ResearchProject/Stochastic-Model-for-DSCA/RECORDED_JULY10/random\"\n",
    "# LAB_PATH = '/scratch/net4/HOS/traces'\n",
    "MAX_ROWS = 10000 #Total Number of rows to be selected\n",
    "ROUND1_START = 20000\n",
    "ROUND1_END = 25000\n",
    "\n",
    "AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA,0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "random_plaintexts = np.loadtxt(os.path.join(LAB_PATH,\"plaintexts.txt\"), dtype=np.uint8, max_rows=MAX_ROWS, converters=type_converter)\n",
    "random_traces = np.loadtxt(os.path.join(LAB_PATH,\"traces.txt\"), max_rows=MAX_ROWS)\n",
    "unscaled_traces = random_traces[:,ROUND1_START:ROUND1_END]\n",
    "SCALE = 3\n",
    "m_off = 0\n",
    "scaled_traces = ((unscaled_traces / 127) * 4) * SCALE + m_off\n",
    "\n",
    "print(\"unscaled traces shape: \", unscaled_traces.shape)\n",
    "print(\"scaled traces shape: \", scaled_traces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d34ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILING = 7500 #Number of traces for profiling \n",
    "ATTACK = 2500 #Number of traces for Attack\n",
    "TYPE = \"bits\" # Type for basis function \"bits\" or \"hw_bits\"\n",
    "MODE = \"S2\" #mode usually S2 (selects top 10 from Norm of Beta)\n",
    "ATTACK_START = 7500 #start of attack traces\n",
    "ATTACK_END = 10000 #end of attack traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1742f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BasisFunctions:\n",
    "    \"\"\"Handles the precomputation of the basis matrix G for a 4-bit S-Box.\"\"\"\n",
    "    def __init__(self, sbox, basis_type='bits'):\n",
    "        self.sbox = sbox\n",
    "        self.num_basis = 5\n",
    "        self.basis_type = basis_type\n",
    "        self.G = self._build_basis_matrix()\n",
    "\n",
    "    def _build_basis_matrix(self):\n",
    "        \"\"\"Precomputes the basis matrix G for all phi values (0-15) based on actual bit value and HW\"\"\"\n",
    "        G = np.zeros((16, self.num_basis), dtype=float)\n",
    "        for phi in range(16):\n",
    "            sbox_output = self.sbox[phi]\n",
    "            if(self.basis_type == 'bits'):\n",
    "                G[phi] = [1.0]+[float(i) for i in format(sbox_output, '04b')]\n",
    "            elif(self.basis_type == 'hw_bits'):\n",
    "                G[phi] = [1.0] + [float(i) for i in format(bin(sbox_output).count('1'),'04b')]\n",
    "        return G\n",
    "\n",
    "class Profiling:\n",
    "    \"\"\"Manages the profiling phase: beta estimation, time point selection, and covariance estimation.\"\"\"\n",
    "    def __init__(self, basis_functions):\n",
    "        self.basis_functions = basis_functions\n",
    "        self.betas = None\n",
    "        self.ts = None\n",
    "        self.cov = None\n",
    "\n",
    "    def estimate_betas(self, traces_prof, x_prof, k_b, start_time, end_time):\n",
    "        \"\"\"Estimates beta coefficients for time points in [start_time:end_time].\"\"\"\n",
    "        N1 = len(x_prof)\n",
    "        phi_prof = np.bitwise_xor(x_prof, k_b) & 0x0F\n",
    "        G_prof = self.basis_functions.G[phi_prof]\n",
    "        segment_length = end_time - start_time\n",
    "        self.betas = np.zeros((segment_length, 5), dtype=float)\n",
    "        self.start_time = start_time\n",
    "        for t_rel, t_abs in enumerate(range(start_time, end_time)):\n",
    "            i_t = traces_prof[:, t_abs]\n",
    "            beta_t, _, _, _ = lstsq(G_prof, i_t, lapack_driver='gelsy')\n",
    "            self.betas[t_rel] = beta_t\n",
    "        return self.betas\n",
    "\n",
    "    def select_time_points(self,betas, tau, selection_mode='S2', traces_prof=None):\n",
    "        \"\"\"Selects relevant time points ts based on the norm of data-dependent betas.\"\"\"\n",
    "        norm_b = np.linalg.norm(betas[:, 1:], axis=1)  # Exclude constant term\n",
    "        # print(f\"Norm of betas: {norm_b}\")\n",
    "        if selection_mode == 'S3':\n",
    "            self.ts = [np.argmax(norm_b)]  # Single max peak\n",
    "        elif selection_mode == 'S2':\n",
    "            self.ts = [int(x) for x in np.argsort(norm_b)[-10:]]  # Top 10 peaks\n",
    "        elif selection_mode == 'S6':\n",
    "            self.ts = np.argsort(norm_b)[-21:]  # Top 21 peaks\n",
    "        elif selection_mode == 'S1':\n",
    "            self.ts = np.where(norm_b >= tau)[0]  # Threshold-based\n",
    "        elif selection_mode in ['S4', 'S5']:\n",
    "            if traces_prof is None:\n",
    "                raise ValueError(\"traces_prof required for S4/S5 selection modes\")\n",
    "            var_t = np.var(traces_prof, axis=0)\n",
    "            mask = (norm_b >= tau) & (norm_b > var_t)\n",
    "            self.ts = np.where(mask)[0]\n",
    "            if selection_mode == 'S5':\n",
    "                extra_mask = (norm_b >= tau / 2) & ~mask\n",
    "                self.ts = np.concatenate((self.ts, np.where(extra_mask)[0]))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown selection_mode: {selection_mode}\")\n",
    "        # self.ts = sorted(self.ts)\n",
    "        return self.ts\n",
    "\n",
    "    def estimate_covariance(self, traces_noise, x_noise, k_b):\n",
    "        \"\"\"Estimates the covariance matrix of residuals for ML key extraction.\"\"\"\n",
    "        N2 = len(x_noise)\n",
    "        m = len(self.ts)\n",
    "        phi_noise = np.bitwise_xor(x_noise, k_b) & 0x0F\n",
    "        G_phi = self.basis_functions.G[phi_noise]  # [N2, 5]\n",
    "        betas_ts = self.betas[self.ts]  # [m, 5]\n",
    "        h_star_all = np.einsum('ij,kj->ik', G_phi, betas_ts)  # [N2, m]\n",
    "        residuals = traces_noise[:, self.ts] - h_star_all\n",
    "        self.cov = np.cov(residuals.T)\n",
    "\n",
    "class KeyExtraction:\n",
    "    \"\"\"Handles key extraction using minimum or maximum likelihood principles.\"\"\"\n",
    "    def __init__(self, profiling):\n",
    "        self.profiling = profiling\n",
    "        self.basis_functions = profiling.basis_functions\n",
    "        self.betas = profiling.betas\n",
    "        self.ts = profiling.ts\n",
    "        self.cov = profiling.cov\n",
    "\n",
    "    def extract_key(self, traces_attack, x_attack,betas, ts,  N3, method='minimum'):\n",
    "        \"\"\"Extracts the subkey using the specified method.\"\"\"\n",
    "        G = self.basis_functions.G\n",
    "        if method == 'minimum':\n",
    "            min_diff = float('inf')\n",
    "            best_k = None\n",
    "            for k_prime in range(16):\n",
    "                diff = 0.0\n",
    "                for j in range(N3):\n",
    "                    phi_j = np.bitwise_xor(x_attack[j], k_prime) & 0x0F\n",
    "                    h_j = np.array([G[phi_j] @ betas[t] for t in ts])\n",
    "                    i_j = traces_attack[j,ts]\n",
    "                    diff += np.sum((i_j - h_j) ** 2)\n",
    "                avg_diff = diff / N3\n",
    "                if avg_diff < min_diff:\n",
    "                    min_diff = avg_diff\n",
    "                    best_k = k_prime\n",
    "            return best_k\n",
    "        elif method == 'ml':\n",
    "            if self.cov is None:\n",
    "                raise ValueError(\"Covariance matrix required for ML method\")\n",
    "            try:\n",
    "                cov_inv = np.linalg.inv(self.cov)\n",
    "            except np.linalg.LinAlgError:\n",
    "                cov_inv = np.linalg.pinv(self.cov)\n",
    "            min_val = float('inf')\n",
    "            best_k = None\n",
    "            for k_prime in range(16):\n",
    "                val = 0.0\n",
    "                for j in range(N3):\n",
    "                    phi_j = np.bitwise_xor(x_attack[j], k_prime) & 0x0F\n",
    "                    h_j = np.array([G[phi_j] @ self.betas[t] for t in self.ts])\n",
    "                    i_j = traces_attack[j, self.ts]\n",
    "                    delta = i_j - h_j\n",
    "                    val += delta.T @ cov_inv @ delta\n",
    "                if val < min_val:\n",
    "                    min_val = val\n",
    "                    best_k = k_prime\n",
    "            return best_k\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    def compute_success_rate(self, traces_attack, x_attack,betas,timepoints, correct_k, sampled=50, num_trials=10, method='minimum'):\n",
    "        \"\"\"Computes the success rate over multiple trials with random subsets.\"\"\"\n",
    "        num_attack = len(x_attack)\n",
    "        success = 0\n",
    "        # print(f\"From the total samples of {num_attack}, {sampled} samples taken at a time and {num_trials} were run to find success rate.\")\n",
    "        for _ in range(num_trials):\n",
    "            indices = random.sample(range(num_attack), sampled)\n",
    "            traces_sub = traces_attack[indices]\n",
    "            x_sub = x_attack[indices]\n",
    "            extracted_k = self.extract_key(traces_sub, x_sub,betas, timepoints, sampled, method)\n",
    "            if extracted_k == correct_k:\n",
    "                success += 1\n",
    "        return (success / num_trials) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0aaee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stochastic_dpa(byte_idx, plaintexts, traces_all, key, start_time, end_time, N1=1000, N2=1000,N3 = 10, tau=0.1, basis_type = 'bits',selection_mode='S2', method='minimum'):\n",
    "    \"\"\"\n",
    "    Run profiling and extraction for one byte within time segment [start_time:end_time].\n",
    "    Assume traces_all [total_samples, length], plaintexts [total_samples, 16]\n",
    "    key: full key nibbles (each 0-15)\n",
    "    Split: 0:N1+N2 for prof, rest for attack\n",
    "    tau: threshold for norm_b\n",
    "    method: 'minimum' or 'ml'\n",
    "    \"\"\"\n",
    "    if not (0 <= start_time < end_time <= traces_all.shape[1]):\n",
    "        raise ValueError(f\"Invalid time segment: [{start_time}:{end_time}]\")\n",
    "    \n",
    "    total_prof = N1 + N2 if method == 'ml' else N1\n",
    "    # if total_prof + N3 > traces_all.shape[0]:\n",
    "    #     raise ValueError(\"Not enough traces for profiling and attack\")\n",
    "    \n",
    "    # byte_idx of all the plain text is taken as column vector\n",
    "    plaintexts_all = plaintexts[:, byte_idx] & 0x0F  # Lower 4 bits\n",
    "    k_b = key[byte_idx] & 0x0F\n",
    "    \n",
    "    traces_prof = traces_all[:total_prof] #shape (total_prof, 5000)\n",
    "    plaintexts_prof = plaintexts_all[:total_prof] #shape(total_prof,)\n",
    "    AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA,0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "\n",
    "    bf = BasisFunctions(AES_SBOX, basis_type=basis_type)\n",
    "    prof = Profiling(bf)\n",
    "    \n",
    "    betas = prof.estimate_betas(traces_prof[:N1], plaintexts_prof[:N1], k_b, start_time, end_time)\n",
    "\n",
    "    if selection_mode in ['S4', 'S5']:\n",
    "        timepoints = prof.select_time_points(betas, tau, selection_mode=selection_mode, traces_prof=traces_prof[:N1])\n",
    "    else:\n",
    "        timepoints = prof.select_time_points(betas, tau, selection_mode=selection_mode)\n",
    "    \n",
    "    # # Estimate covariance for ML\n",
    "    if method == 'ml':\n",
    "        traces_noise = traces_prof[N1:N1 + N2]\n",
    "        x_noise = plaintexts_prof[N1:N1 + N2]\n",
    "        prof.estimate_covariance(traces_noise, x_noise, k_b)\n",
    "    \n",
    "    # After profiling next N3 traces are taken for attack\n",
    "    traces_attack = traces_all[total_prof:total_prof + N3]\n",
    "    plaintext_attack = plaintexts_all[total_prof:total_prof + N3]\n",
    "    \n",
    "    ke = KeyExtraction(prof)\n",
    "    extracted_k = ke.extract_key(traces_attack, plaintext_attack, betas, timepoints, N3, method=method)\n",
    "    if(extracted_k==k_b):\n",
    "        sr = ke.compute_success_rate(traces_all[total_prof:], plaintexts_all[total_prof:],betas,timepoints, k_b, sampled=50, num_trials=10, method=method)\n",
    "        # [ke.betas[i].tolist() for i in ke.ts]\n",
    "        return extracted_k, ke.ts, ke.betas,sr\n",
    "    else:\n",
    "        return extracted_k,ke.ts, ke.betas,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736b1387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_range(start_time=0, end_time=5000, increments=[5,10], widths=[10,20]):\n",
    "    ranges = set()\n",
    "    for inc in increments:\n",
    "        s = start_time\n",
    "        while True:\n",
    "            for w in widths:\n",
    "                end = s + w\n",
    "                if end > end_time:\n",
    "                    break\n",
    "                ranges.add((s, end))\n",
    "            s += inc\n",
    "            if s + min(widths) > end:\n",
    "                break\n",
    "    return sorted(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa619556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for byte index 0\n",
      "Running for byte index 1\n",
      "Running for byte index 2\n",
      "Running for byte index 3\n",
      "Running for byte index 4\n",
      "Running for byte index 5\n",
      "Running for byte index 6\n",
      "Running for byte index 7\n",
      "Running for byte index 8\n",
      "Running for byte index 9\n",
      "Running for byte index 10\n",
      "Running for byte index 11\n",
      "Running for byte index 12\n",
      "Running for byte index 13\n",
      "Running for byte index 14\n",
      "Running for byte index 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "key = np.array([15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0], dtype=np.uint8)\n",
    "df_data = []\n",
    "for k in range(16): # change here to run for all 16 bytes\n",
    "    print(f\"Running for byte index {k}\")\n",
    "    ranges = create_range(start_time=0, end_time=5000, increments=[10], widths=[10,15,20])\n",
    "    for r in (ranges):\n",
    "        results = []\n",
    "        extracted_k, ts, betas, sr = run_stochastic_dpa(\n",
    "            byte_idx=k,\n",
    "            plaintexts=random_plaintexts,\n",
    "            traces_all=scaled_traces,\n",
    "            key=key,\n",
    "            start_time=r[0],\n",
    "            end_time=r[1],\n",
    "            N1=PROFILING,\n",
    "            N2=200,\n",
    "            N3= ATTACK,\n",
    "            tau=0.1,\n",
    "            basis_type= TYPE,\n",
    "            selection_mode=MODE,\n",
    "            method='minimum'\n",
    "        )\n",
    "        if(extracted_k ==key[k] and sr>0):\n",
    "            df_data.append({\n",
    "                'byte_idx': k,\n",
    "                'range':r,\n",
    "                'extracted_key': extracted_k,\n",
    "                'time_points': ts,\n",
    "                'betas': betas,\n",
    "                'sr':float(sr)\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(df_data)\n",
    "df.to_csv(f'RESULTS_{PROFILING}_{TYPE}_{MODE}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1da8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attack:\n",
    "    \"\"\"Handles key extraction using minimum or maximum likelihood principles.\"\"\"\n",
    "    def __init__(self, basis_functions, betas, ts, cov=None):\n",
    "        self.basis_functions = basis_functions\n",
    "        self.betas = betas\n",
    "        self.ts = ts\n",
    "        self.cov = cov\n",
    "\n",
    "    def extract_key(self, traces_attack, plaintexts_attack, byte_idx,N3, method='minimum'):\n",
    "        \"\"\"Extracts the subkey using the specified method.\"\"\"\n",
    "        m = len(self.ts)\n",
    "        G = self.basis_functions.G\n",
    "        plaintexts_attack = plaintexts_attack[:, byte_idx] & 0x0F\n",
    "        if method == 'minimum':\n",
    "            min_diff = float('inf')\n",
    "            best_k = None\n",
    "            for k_prime in range(16):\n",
    "                diff = 0.0\n",
    "                for j in range(N3):\n",
    "                    phi_j = np.bitwise_xor(plaintexts_attack[j], k_prime) & 0x0F\n",
    "                    h_j = np.array([G[phi_j] @self.betas[t] for t in self.ts])\n",
    "                    i_j = traces_attack[j, self.ts]\n",
    "                    diff += np.sum((i_j - h_j) ** 2)\n",
    "                avg_diff = diff / N3\n",
    "                if avg_diff < min_diff:\n",
    "                    min_diff = avg_diff\n",
    "                    best_k = k_prime\n",
    "            return best_k\n",
    "        elif method == 'ml':\n",
    "            if self.cov is None:\n",
    "                raise ValueError(\"Covariance matrix required for ML method\")\n",
    "            try:\n",
    "                cov_inv = np.linalg.inv(self.cov)\n",
    "            except np.linalg.LinAlgError:\n",
    "                cov_inv = np.linalg.pinv(self.cov)\n",
    "            min_val = float('inf')\n",
    "            best_k = None\n",
    "            for k_prime in range(16):\n",
    "                val = 0.0\n",
    "                for j in range(N3):\n",
    "                    phi_j = np.bitwise_xor(plaintexts_attack[j], k_prime) & 0x0F\n",
    "                    h_j = np.array([G[phi_j] @ self.betas[t] for t in self.ts])\n",
    "                    i_j = traces_attack[j, self.ts]\n",
    "                    delta = i_j - h_j\n",
    "                    val += delta.T @ cov_inv @ delta\n",
    "                if val < min_val:\n",
    "                    min_val = val\n",
    "                    best_k = k_prime\n",
    "            return best_k\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    def compute_success_rate(self, traces_attack, \n",
    "                             plaintexts_attack, \n",
    "                             correct_k, \n",
    "                             sampled=50, \n",
    "                             num_trials=10, method='minimum'):\n",
    "        \"\"\"Computes the success rate over multiple trials with random subsets.\"\"\"\n",
    "        num_attack = len(plaintexts_attack)\n",
    "        success = 0\n",
    "        print(f\"From the total samples of {num_attack}, {sampled} samples taken at a time and {num_trials} were run to find success rate.\")\n",
    "        for _ in range(num_trials):\n",
    "            indices = random.sample(range(num_attack), sampled)\n",
    "            traces_sub = traces_attack[indices]\n",
    "            x_sub = plaintexts_attack[indices]\n",
    "            extracted_k = self.extract_key(traces_sub, x_sub, sampled, method)\n",
    "            if extracted_k == correct_k:\n",
    "                success += 1\n",
    "        return (success / num_trials) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4898e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_plaintexts = random_plaintexts[ATTACK_START:ATTACK_END] \n",
    "attack_traces = scaled_traces[ATTACK_START:ATTACK_END]\n",
    "final_expected = {}\n",
    "for byte_idx in range(16): # change here to run for all 16 bytes\n",
    "    byte = [d for d in df_data if d['byte_idx'] == byte_idx]\n",
    "    count = {i: 0 for i in range(16)}\n",
    "    for idx in byte:\n",
    "        betas, ts = idx['betas'], idx['time_points']\n",
    "        bf_attack = BasisFunctions(AES_SBOX, basis_type=TYPE)\n",
    "        attack = Attack(bf_attack,betas, ts)\n",
    "        e_k = attack.extract_key(attack_traces, attack_plaintexts,byte_idx, 10,method='minimum')\n",
    "        count[e_k] = count[e_k]+1\n",
    "    filtered = {k: v for k, v in count.items() if v}\n",
    "    final_expected[byte_idx] = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fc2951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [7, 10, 11], 1: [3, 12, 0], 2: [14, 15, 2], 3: [9, 15, 13], 4: [12, 15, 9], 5: [10, 9, 12], 6: [15, 10, 7], 7: [0, 3, 12], 8: [8, 1, 7], 9: [15, 1, 9], 10: [0, 13, 1], 11: [2, 7, 8], 12: [4, 2, 14], 13: [8, 11, 12], 14: [10, 2, 1], 15: [0, 1, 14]}\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "topN = {k: [x for x, _ in sorted(v.items(), key=lambda item: item[1], reverse=True)[:N]]\n",
    "        for k, v in final_expected.items()}\n",
    "print(topN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd9967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3fbc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
