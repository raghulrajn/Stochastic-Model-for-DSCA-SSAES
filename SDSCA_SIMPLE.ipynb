{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4fb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy pandas scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e96593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "type_converter = {i: lambda x: int(x, 16) for i in range(16)}\n",
    "LAB_PATH = \"/scratch/net4/HOS/Traces\"\n",
    "ATTACK_PATH = \"/home/navanerj/Downloads/ATTACK\"\n",
    "MAX_ROWS = 30000 #Total Number of rows to be selected\n",
    "ROUND1_START = 20000\n",
    "ROUND1_END = 25000\n",
    "SCALE = 3\n",
    "m_off = 0\n",
    "AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA,0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "random_plaintexts = np.loadtxt(os.path.join(LAB_PATH,\"plaintexts.txt\"), dtype=np.uint8, max_rows=MAX_ROWS, converters=type_converter)\n",
    "random_ciphertexts = np.loadtxt(os.path.join(LAB_PATH,\"ciphertexts.txt\"), dtype=np.uint8, max_rows=MAX_ROWS, converters=type_converter)\n",
    "random_traces = np.loadtxt(os.path.join(LAB_PATH,\"traces.txt\"), max_rows=MAX_ROWS)\n",
    "unscaled_traces = random_traces[:,ROUND1_START:ROUND1_END]\n",
    "\n",
    "scaled_traces = ((unscaled_traces / 127) * 4) * SCALE + m_off\n",
    "\n",
    "print(\"unscaled traces shape: \", unscaled_traces.shape)\n",
    "print(\"scaled traces shape: \", scaled_traces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c848152",
   "metadata": {},
   "source": [
    "## Stochastic Model for DSCA \n",
    "- Constructing Basis functions\n",
    "- Profiling based on SBOX output of 1st round\n",
    "- Key Extraction based on minimum residual error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce104c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq, pinv\n",
    "import random\n",
    "from numpy import linalg\n",
    "\n",
    "class BasisFunctions:\n",
    "    \"\"\"Handles the precomputation of the basis matrix G for a 4-bit S-Box.\"\"\"\n",
    "    def __init__(self, sbox, basis_type='bits'):\n",
    "        self.sbox = sbox\n",
    "        if basis_type in [\"hw\", \"lsb\"]:\n",
    "            self.num_basis = 2\n",
    "        else:\n",
    "            self.num_basis = 5\n",
    "        self.basis_type = basis_type\n",
    "        self.G = self._build_basis_matrix()\n",
    "\n",
    "    def _build_basis_matrix(self):\n",
    "        \"\"\"Precomputes the basis matrix G for all phi values (0-15) based on actual bit value and HW\"\"\"\n",
    "        G = np.zeros((16, self.num_basis), dtype=float)\n",
    "        for phi in range(16):\n",
    "            sbox_output = self.sbox[phi]\n",
    "            if(self.basis_type == 'bits'):\n",
    "                G[phi] = [1.0]+[float(i) for i in format(sbox_output, '04b')]\n",
    "            elif(self.basis_type == 'hw_bits'):\n",
    "                G[phi] = [1.0] + [float(i) for i in format(bin(sbox_output).count('1'),'04b')]\n",
    "            elif(self.basis_type == 'hw'):\n",
    "                G[phi] = [1.0] + [float(bin(sbox_output).count('1'))]\n",
    "            elif(self.basis_type == 'lsb'):\n",
    "                G[phi] = [1.0, float(sbox_output & 1)]\n",
    "        return G\n",
    "\n",
    "class Profiling:\n",
    "    \"\"\"Manages the profiling phase: beta estimation, time point selection, and covariance estimation.\"\"\"\n",
    "    def __init__(self, basis_functions):\n",
    "        self.basis_functions = basis_functions\n",
    "        self.betas = None\n",
    "        self.ts = None\n",
    "        self.cov = None\n",
    "\n",
    "    def estimate_betas(self, traces_prof, x_prof, k_b, start_time, end_time):\n",
    "        phi_prof = np.bitwise_xor(x_prof, k_b) & 0x0F\n",
    "        G_prof = self.basis_functions.G[phi_prof]  # shape (N1, num_basis)\n",
    "        I = traces_prof[:, start_time:end_time]  # shape (N1, segment_length)\n",
    "        G_pinv = pinv(G_prof)\n",
    "        betas = G_pinv @ I    # Shape (num_basis, segment_length)\n",
    "        self.betas = betas.T  # Match old shape (segment_length, num_basis)\n",
    "        self.start_time = start_time\n",
    "        return self.betas\n",
    "\n",
    "    def select_time_points(self,betas, tau,N = 15, selection_mode='S2', traces_prof=None):\n",
    "        \"\"\"Selects relevant time points ts based on the norm of data-dependent betas.\"\"\"\n",
    "        norm_b = np.linalg.norm(betas[:, 1:], axis=1)  # Exclude constant term\n",
    "        if selection_mode == 'S3':\n",
    "            self.ts = [np.argmax(norm_b)]  #Single max peak\n",
    "        elif selection_mode == 'S2':\n",
    "            self.ts = [int(x) for x in np.argsort(norm_b)[-N:]]  # Top N peaks\n",
    "        elif selection_mode == 'S1':\n",
    "            self.ts = np.where(norm_b >= tau)[0]  #Threshold-based\n",
    "        elif selection_mode in ['S4', 'S5']:\n",
    "            if traces_prof is None:\n",
    "                raise ValueError(\"traces_prof required for S4/S5 selection modes\")\n",
    "            var_t = np.var(traces_prof, axis=0)\n",
    "            mask = (norm_b >= tau) & (norm_b > var_t)\n",
    "            self.ts = np.where(mask)[0]\n",
    "            if selection_mode == 'S5':\n",
    "                extra_mask = (norm_b >= tau / 2) & ~mask\n",
    "                self.ts = np.concatenate((self.ts, np.where(extra_mask)[0]))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown selection_mode: {selection_mode}\")\n",
    "        return self.ts\n",
    "    \n",
    "    def detect_noise(self, traces_prof, x_prof, k_b):\n",
    "        \"\"\"Detect noise levels using residuals after beta fitting.\"\"\"\n",
    "        if self.betas is None:\n",
    "            raise ValueError(\"Run estimate_betas first\")\n",
    "        # Compute predicted h_t for all t in segment\n",
    "        phi_prof = np.bitwise_xor(x_prof, k_b) & 0x0F\n",
    "        G_prof = self.basis_functions.G[phi_prof]  # N1 x num_basis\n",
    "        h_pred = np.dot(G_prof, self.betas.T)  # N1 x segment_length\n",
    "        segment_traces = traces_prof[:, self.start_time:self.start_time + len(self.betas)]\n",
    "        residuals = segment_traces - h_pred\n",
    "        # Noise metrics\n",
    "        noise_var = np.var(residuals)  # Overall var(R_t)\n",
    "        signal_var = np.var(h_pred)    # var(h_t)\n",
    "        snr = signal_var / noise_var if noise_var > 0 else float('inf')\n",
    "        # Per-time variance\n",
    "        noise_var_per_t = np.var(residuals, axis=0)  # segment_length x 1\n",
    "        return snr, noise_var, noise_var_per_t\n",
    "    \n",
    "    def estimate_covariance(self, traces_noise, x_noise, k_b):\n",
    "        \"\"\"Estimates the covariance matrix of residuals for ML key extraction.\"\"\"\n",
    "        N2 = len(x_noise)\n",
    "        m = len(self.ts)\n",
    "        phi_noise = np.bitwise_xor(x_noise, k_b) & 0x0F\n",
    "        G_phi = self.basis_functions.G[phi_noise]  # [N2, 5]\n",
    "        betas_ts = self.betas[self.ts]  # [m, 5]\n",
    "        h_star_all = np.einsum('ij,kj->ik', G_phi, betas_ts)  # [N2, m]\n",
    "        residuals = traces_noise[:, self.ts] - h_star_all\n",
    "        self.cov = np.cov(residuals.T)\n",
    "\n",
    "class KeyExtraction:\n",
    "    \"\"\"Handles key extraction using minimum or maximum likelihood principles.\"\"\"\n",
    "    def __init__(self, profiling):\n",
    "        self.profiling = profiling\n",
    "        self.basis_functions = profiling.basis_functions\n",
    "        self.betas = profiling.betas\n",
    "        self.ts = profiling.ts\n",
    "        self.cov = profiling.cov\n",
    "\n",
    "    def extract_key(self, traces_attack, x_attack,betas, ts,  N3, method='minimum'):\n",
    "        \"\"\"Extracts the subkey using the specified method.\"\"\"\n",
    "        extracted_key = {i: 0 for i in range(16)}\n",
    "        num_candidates = 16\n",
    "        key_scores = np.zeros(num_candidates)\n",
    "        G = self.basis_functions.G\n",
    "        betas_ts = betas[ts]\n",
    "        if method == 'minimum':\n",
    "            min_diff = float('inf')\n",
    "            best_k = None\n",
    "            for k_prime in range(num_candidates):\n",
    "                diff = 0.0\n",
    "                for j in range(N3):\n",
    "                    phi_j = np.bitwise_xor(x_attack[j], k_prime) & 0x0F\n",
    "                    h_j = betas_ts @ G[phi_j]\n",
    "                    i_j = traces_attack[j, ts]\n",
    "                    diff += np.sum((i_j - h_j) ** 2)\n",
    "                avg_diff = diff / N3\n",
    "                if avg_diff < min_diff:\n",
    "                    min_diff = avg_diff\n",
    "                    best_k = k_prime\n",
    "                    extracted_key[k_prime] = extracted_key[best_k] + 1\n",
    "            return best_k, extracted_key\n",
    "        \n",
    "        elif method == 'maximum':\n",
    "            if self.cov is None:\n",
    "                raise ValueError(\"Covariance matrix not available. Estimate it in profiling first.\")\n",
    "\n",
    "            # Precompute covariance inverse and determinant for Gaussian PDF\n",
    "            try:\n",
    "                C_inv = np.linalg.inv(self.cov)\n",
    "            except np.linalg.LinAlgError:\n",
    "                C_inv = np.linalg.pinv(self.cov)\n",
    "            best_k = None\n",
    "            for k_prime in range(num_candidates):\n",
    "                val = 0.0\n",
    "                for j in range(N3):\n",
    "                    phi_j = np.bitwise_xor(x_attack[j], k_prime) & 0x0F\n",
    "                    h_j = betas_ts @ G[phi_j]     # Predicted deterministic leakage\n",
    "                    i_j = traces_attack[j, ts]    # Measured leakage\n",
    "                    delta = i_j - h_j             # Residual noise vector\n",
    "                    val += delta.T @ C_inv @ delta\n",
    "                key_scores[k_prime] = val\n",
    "\n",
    "            top_k_indices = np.argsort(key_scores)[:5]\n",
    "            top_k_scores = key_scores[top_k_indices]\n",
    "            top_candidates = {int(k): float(s) for k, s in zip(top_k_indices, top_k_scores)}\n",
    "            return int(top_k_indices[0]), top_candidates\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "\n",
    "    def compute_success_rate(self, traces_attack, x_attack,betas,timepoints, correct_k, sampled=50, num_trials=10, method='minimum'):\n",
    "        \"\"\"Computes the success rate over multiple trials with random subsets.\"\"\"\n",
    "        num_attack = len(x_attack)\n",
    "        success = 0\n",
    "        for _ in range(num_trials):\n",
    "            indices = random.sample(range(num_attack), sampled)\n",
    "            traces_sub = traces_attack[indices]\n",
    "            x_sub = x_attack[indices]\n",
    "            extracted_k = self.extract_key(traces_sub, x_sub,betas, timepoints, sampled, method)\n",
    "            if extracted_k == correct_k:\n",
    "                success += 1\n",
    "        return (success / num_trials) * 100\n",
    "    \n",
    "def create_range(start_time=0, end_time=5000, increments=(5, 10), widths=(10, 20)):\n",
    "    ranges = set()\n",
    "    widths = tuple(sorted(widths))\n",
    "    min_w = widths[0]\n",
    "\n",
    "    for inc in increments:\n",
    "        s = start_time\n",
    "        while s + min_w <= end_time:\n",
    "            for w in widths:\n",
    "                end = s + w\n",
    "                if end > end_time:\n",
    "                    break\n",
    "                ranges.add((s, end))\n",
    "            s += inc\n",
    "    return sorted(ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5394e6fb",
   "metadata": {},
   "source": [
    "## Profiling and Key Extraction using Known Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b071d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SDSCA as sd\n",
    "total_prof = 5000\n",
    "key = np.array([15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0], dtype=np.uint8)\n",
    "ATTACK_START = 15000\n",
    "ATTACK_END = 19000\n",
    "TOTAL_ATTACK = ATTACK_END - ATTACK_START\n",
    "PROF_START = 0\n",
    "PROF_END = 5000\n",
    "correct_count = 0\n",
    "top_n = 4\n",
    "results = []\n",
    "METHOD = \"maximum\"\n",
    "N_POINTS = 15\n",
    "for byte_idx in range(16):\n",
    "    plaintexts_all = random_plaintexts[:, byte_idx] & 0x0F  # Lower 4 bits\n",
    "    k_b = key[byte_idx] & 0x0F\n",
    "    traces_prof = scaled_traces[:total_prof]\n",
    "    plaintexts_prof = plaintexts_all[:total_prof]\n",
    "    AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA,0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "    bf = BasisFunctions(AES_SBOX, basis_type=\"hw\")\n",
    "    prof = Profiling(bf)\n",
    "    betas = prof.estimate_betas(traces_prof, plaintexts_prof, k_b,PROF_START, PROF_END)\n",
    "    timepoints = prof.select_time_points(betas, 0.1,N=N_POINTS,  selection_mode=\"S2\")\n",
    "    traces_attack = scaled_traces[ATTACK_START:ATTACK_END]\n",
    "    plaintexts_attack = plaintexts_all[ATTACK_START:ATTACK_END]\n",
    "\n",
    "    if METHOD == \"maximum\":\n",
    "        SNR , NOISE_VAR, NOISE_PER_T = [],[],[]\n",
    "        snr, noise_var, noise_var_per_t = prof.detect_noise(traces_prof, plaintexts_prof, k_b)\n",
    "        SNR.append(snr)\n",
    "        NOISE_VAR.append(noise_var)\n",
    "        NOISE_PER_T.append(noise_var_per_t)\n",
    "        prof.estimate_covariance(traces_prof, plaintexts_prof, k_b)\n",
    "    ke = KeyExtraction(prof)\n",
    "    extracted_k, exp_keys = ke.extract_key(traces_attack, plaintexts_attack, betas, timepoints, TOTAL_ATTACK, method=METHOD)\n",
    "    filtered = {k: v for k, v in exp_keys.items() if v}\n",
    "    if key[byte_idx] in filtered.keys():\n",
    "        correct_count += 1\n",
    "    sorted_candidates = sorted(filtered.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_candidates = [int(k) for k, _ in sorted_candidates]\n",
    "\n",
    "    correct_key = int(key[byte_idx])\n",
    "    if correct_key==extracted_k:\n",
    "        success = True\n",
    "        correct_count += 1\n",
    "    else:\n",
    "        success = any((cand is not None and int(cand) == int(correct_key)) for cand in top_candidates)\n",
    "\n",
    "    row = {\n",
    "        \"byte\": byte_idx,\n",
    "        \"correct_key\": correct_key,\n",
    "        \"extracted_key\": int(extracted_k),\n",
    "        \"candidates\": top_candidates,\n",
    "        \"success\": success\n",
    "    }\n",
    "    results.append(row)\n",
    "\n",
    "df_attack = pd.DataFrame(results,\n",
    "                         columns=[\"byte\", \"correct_key\", \"extracted_key\",\n",
    "                                  \"candidates\",\"success\"])\n",
    "\n",
    "success_rate = (int(df_attack['success'].sum()) / 16) * 100\n",
    "print(f\"Overall Success Rate: {success_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf1883",
   "metadata": {},
   "source": [
    "## Profiling and Key Extraction using Unknown Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3fbc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prof = 10000\n",
    "ATTACK_START = 15000\n",
    "ATTACK_END = 20000\n",
    "TOTAL_ATTACK = ATTACK_END - ATTACK_START\n",
    "PROF_START = 0\n",
    "PROF_END = 5000\n",
    "METHOD=\"maximum\"\n",
    "N_POINTS = 20\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    use_tqdm = True\n",
    "except Exception:\n",
    "    use_tqdm = False\n",
    "\n",
    "byte_iter = range(16)\n",
    "if use_tqdm:\n",
    "    byte_iter = tqdm(byte_iter, desc=\"bytes\")\n",
    "top_n = 5\n",
    "AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA, 0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "key = np.array([15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0], dtype=np.uint8)\n",
    "best_candidates_per_byte = {} \n",
    "candidate_range = range(16)\n",
    "\n",
    "for byte_idx in byte_iter:\n",
    "    plaintexts_all = random_plaintexts[:, byte_idx] & 0x0F\n",
    "    traces_prof = scaled_traces[:total_prof]\n",
    "    plaintexts_prof = plaintexts_all[:total_prof]\n",
    "\n",
    "    candidate_scores = []\n",
    "\n",
    "    for cand in candidate_range:\n",
    "        k_b = int(cand & 0x0F)\n",
    "\n",
    "        bf = BasisFunctions(AES_SBOX, basis_type=\"hw\")\n",
    "        prof = Profiling(bf)\n",
    "\n",
    "        try:\n",
    "            betas = prof.estimate_betas(traces_prof, plaintexts_prof, k_b, PROF_START, PROF_END)\n",
    "        except Exception as e:\n",
    "            print(f\"[byte {byte_idx} cand {cand}] estimate_betas failed: {e}\")\n",
    "            continue\n",
    "        try:\n",
    "            timepoints = prof.select_time_points(betas, 0.1,N=N_POINTS, selection_mode=\"S2\")\n",
    "        except Exception as e:\n",
    "            print(f\"[byte {byte_idx} cand {cand}] select_time_points failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        traces_attack = scaled_traces[ATTACK_START:ATTACK_END]\n",
    "        plaintexts_attack = plaintexts_all[ATTACK_START:ATTACK_END]\n",
    "\n",
    "        if METHOD == \"maximum\":\n",
    "            SNR , NOISE_VAR, NOISE_PER_T = [],[],[]\n",
    "            snr, noise_var, noise_var_per_t = prof.detect_noise(traces_prof, plaintexts_prof, k_b)\n",
    "            SNR.append(snr)\n",
    "            NOISE_VAR.append(noise_var)\n",
    "            NOISE_PER_T.append(noise_var_per_t)\n",
    "            prof.estimate_covariance(traces_prof, plaintexts_prof, k_b)\n",
    "\n",
    "        ke = KeyExtraction(prof)\n",
    "        try:\n",
    "            extracted_k, exp_keys = ke.extract_key(traces_attack, plaintexts_attack, betas, timepoints, TOTAL_ATTACK, method=\"minimum\")\n",
    "        except Exception as e:\n",
    "            print(f\"[byte {byte_idx} cand {cand}] extract_key failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Score the candidate:\n",
    "        # use extracted_key.get(cand,0) as the primary score, plus a bonus if extracted_k == cand.\n",
    "        score = 0.0\n",
    "        try:\n",
    "            if isinstance(exp_keys, dict):\n",
    "                score = float(exp_keys.get(cand, 0))\n",
    "            else:\n",
    "                # give small score if extracted_k equals candidate\n",
    "                score = 1.0 if extracted_k == cand else 0.0\n",
    "        except Exception:\n",
    "            score = 0.0\n",
    "\n",
    "        # Strong bonus if the returned extracted_k equals this candidate (means this run found this nibble)\n",
    "        if extracted_k == cand:\n",
    "            score += 10.0\n",
    "        try:\n",
    "            exp_keys_snapshot = dict(exp_keys) if isinstance(exp_keys, dict) else {\"value\": exp_keys}\n",
    "        except Exception:\n",
    "            exp_keys_snapshot = {\"unserializable\": str(type(exp_keys))}\n",
    "\n",
    "        candidate_scores.append((cand, score, extracted_k, exp_keys_snapshot))\n",
    "\n",
    "    # sort and keep top_n\n",
    "    candidate_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    best_candidates_per_byte[byte_idx] = candidate_scores[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 4\n",
    "csv_filename = \"byte_top4_separate_cols.csv\"\n",
    "all_success = True\n",
    "success_count = 0\n",
    "result_rows = []\n",
    "for b in range(16):\n",
    "    # get correct key nibble if `key` exists in scope, else None\n",
    "    try:\n",
    "        correct_key = int(key[b])\n",
    "    except Exception:\n",
    "        correct_key = None\n",
    "\n",
    "    cand_list = best_candidates_per_byte.get(b, [])\n",
    "    top_candidates = [int(t[0]) for t in cand_list[:top_k]]\n",
    "    if len(top_candidates) < top_k:\n",
    "        top_candidates += [None] * (top_k - len(top_candidates))\n",
    "\n",
    "    if correct_key is None:\n",
    "        success = False\n",
    "    else:\n",
    "        success = any((cand is not None and int(cand) == int(correct_key)) for cand in top_candidates)\n",
    "\n",
    "    if success:\n",
    "        success_count += 1\n",
    "    else:\n",
    "        all_success = False\n",
    "\n",
    "    row = {\n",
    "        \"byte\": b,\n",
    "        \"correct_key\": correct_key,\n",
    "        \"candidates\":top_candidates,\n",
    "        \"cand_1\": top_candidates[0],\n",
    "        \"cand_2\": top_candidates[1],\n",
    "        \"cand_3\": top_candidates[2],\n",
    "        \"cand_4\": top_candidates[3],\n",
    "        \"success\": success\n",
    "    }\n",
    "    result_rows.append(row)\n",
    "\n",
    "df_top4 = pd.DataFrame(result_rows, columns=[\"byte\", \"correct_key\", \"cand_1\", \"cand_2\", \"cand_3\", \"cand_4\", \"success\"])\n",
    "df_top4.to_csv(csv_filename, index=False)\n",
    "\n",
    "if all_success and success_count == 16:\n",
    "    print(\"Key recovered successfully ✅\")\n",
    "else:\n",
    "    print(f\"Key recovery incomplete: {success_count}/16 bytes matched one of the top-{top_k} candidates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e87ab8d",
   "metadata": {},
   "source": [
    "ATTACK - CUSTOM\n",
    "\n",
    "Profile 5000 Attack 3000 Correct key 12/16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ecd9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "import pickle\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Util.Padding import pad\n",
    "\n",
    "plaintext_hex = ''.join([f'{x:x}' for x in random_plaintexts[0]])\n",
    "ciphertext_hex_target = ''.join([f'{x:x}' for x in random_ciphertexts[0]])\n",
    "\n",
    "def aes_encrypt_with_keybytes(key_bytes: bytes, plaintext_bytes: bytes) -> str:\n",
    "    padded = pad(plaintext_bytes, AES.block_size)\n",
    "    print(\"Padded Plaintext (hex):\", padded.hex())\n",
    "    cipher = AES.new(key_bytes, AES.MODE_ECB)\n",
    "    ct = cipher.encrypt(padded)\n",
    "    return ct.hex()\n",
    "\n",
    "def parse_candidates_field(val):\n",
    "    \"\"\"\n",
    "    Safely parse a 'candidates' cell which might already be a list or might be a string representation.\n",
    "    If parsing fails, return None.\n",
    "    \"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "    if isinstance(val, (list, tuple, set)):\n",
    "        return [int(x) for x in val]\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(val)\n",
    "            if isinstance(parsed, (list, tuple, set)):\n",
    "                return [int(x) for x in parsed]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "base_key_bytes = df_attack[\"extracted_key\"].tolist()\n",
    "if len(base_key_bytes) != 16:\n",
    "    raise ValueError(\"Expecting `key` to contain 16 elements (one per byte).\")\n",
    "\n",
    "# ---------- find failed indices ----------\n",
    "failed_rows = []\n",
    "if 'df_attack' in globals() and 'success' in df_attack.columns:\n",
    "    failed_rows = df_attack[df_attack['success'] == False].to_dict('records')\n",
    "\n",
    "if not failed_rows:\n",
    "    print(\"No failed indices found (no rows with success==False). Nothing to brute-force.\")\n",
    "else:\n",
    "    print(\"Failed rows (to brute-force):\", [r['byte'] for r in failed_rows])\n",
    "\n",
    "bruteforce_results = []  # list of dicts: {byte, candidate, ciphertext, match (bool)}\n",
    "\n",
    "for row in failed_rows:\n",
    "    b = int(row.get(\"byte\"))\n",
    "    # Get candidate list from the DataFrame row if present; else try full 0..15\n",
    "    raw_candidates = row.get(\"candidates\", None)\n",
    "    candidates = parse_candidates_field(raw_candidates)\n",
    "    if not candidates:\n",
    "        candidates = list(range(16))\n",
    "\n",
    "    print(f\"\\nBrute-forcing byte index {b} with candidates: {candidates}\")\n",
    "\n",
    "    found_match_for_byte = False\n",
    "    plaintext_bytes = bytes.fromhex(''.join([f'{x:02x}' for x in random_plaintexts[0]]))\n",
    "    for cand in candidates:\n",
    "        candidate_key = base_key_bytes       # copy base key\n",
    "        candidate_key[b] = int(cand)                # replace that byte with candidate nibble\n",
    "        key_bytes = bytes.fromhex(''.join([f'{x:02x}' for x in candidate_key]))            # 16-byte AES key\n",
    "        ct_hex = aes_encrypt_with_keybytes(key_bytes, plaintext_bytes)\n",
    "        print(ct_hex)\n",
    "        is_match = False\n",
    "        if ciphertext_hex_target is not None:\n",
    "            if ct_hex.lower() == ciphertext_hex_target.lower():\n",
    "                is_match = True\n",
    "                found_match_for_byte = True\n",
    "                print(f\"  -> MATCH! byte {b} candidate {cand} -> key = {key_bytes.hex()} -> ciphertext = {ct_hex}\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"  cand {cand:2d}: ciphertext = {ct_hex}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
