{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4fb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy pandas scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e96593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unscaled traces shape:  (30000, 5000)\n",
      "scaled traces shape:  (30000, 5000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "type_converter = {i: lambda x: int(x, 16) for i in range(16)}\n",
    "LAB_PATH = \"/scratch/net4/HOS/Traces\"\n",
    "MAX_ROWS = 30000 #Total Number of rows to be selected\n",
    "ROUND1_START = 20000\n",
    "ROUND1_END = 25000\n",
    "SCALE = 3\n",
    "m_off = 0\n",
    "AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA,0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "random_plaintexts = np.loadtxt(os.path.join(LAB_PATH,\"plaintexts.txt\"), dtype=np.uint8, max_rows=MAX_ROWS, converters=type_converter)\n",
    "random_traces = np.loadtxt(os.path.join(LAB_PATH,\"traces.txt\"), max_rows=MAX_ROWS)\n",
    "unscaled_traces = random_traces[:,ROUND1_START:ROUND1_END]\n",
    "\n",
    "scaled_traces = ((unscaled_traces / 127) * 4) * SCALE + m_off\n",
    "\n",
    "print(\"unscaled traces shape: \", unscaled_traces.shape)\n",
    "print(\"scaled traces shape: \", scaled_traces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce104c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq, pinv\n",
    "import random\n",
    "\n",
    "class BasisFunctions:\n",
    "    \"\"\"Handles the precomputation of the basis matrix G for a 4-bit S-Box.\"\"\"\n",
    "    def __init__(self, sbox, basis_type='bits'):\n",
    "        self.sbox = sbox\n",
    "        if basis_type in [\"hw\", \"lsb\"]:\n",
    "            self.num_basis = 2\n",
    "        else:\n",
    "            self.num_basis = 5\n",
    "        self.basis_type = basis_type\n",
    "        self.G = self._build_basis_matrix()\n",
    "\n",
    "    def _build_basis_matrix(self):\n",
    "        \"\"\"Precomputes the basis matrix G for all phi values (0-15) based on actual bit value and HW\"\"\"\n",
    "        G = np.zeros((16, self.num_basis), dtype=float)\n",
    "        for phi in range(16):\n",
    "            sbox_output = self.sbox[phi]\n",
    "            if(self.basis_type == 'bits'):\n",
    "                G[phi] = [1.0]+[float(i) for i in format(sbox_output, '04b')]\n",
    "            elif(self.basis_type == 'hw_bits'):\n",
    "                G[phi] = [1.0] + [float(i) for i in format(bin(sbox_output).count('1'),'04b')]\n",
    "            elif(self.basis_type == 'hw'):\n",
    "                G[phi] = [1.0] + [float(bin(sbox_output).count('1'))]\n",
    "            elif(self.basis_type == 'lsb'):\n",
    "                G[phi] = [1.0, float(sbox_output & 1)]\n",
    "        return G\n",
    "\n",
    "class Profiling:\n",
    "    \"\"\"Manages the profiling phase: beta estimation, time point selection, and covariance estimation.\"\"\"\n",
    "    def __init__(self, basis_functions):\n",
    "        self.basis_functions = basis_functions\n",
    "        self.betas = None\n",
    "        self.ts = None\n",
    "        self.cov = None\n",
    "\n",
    "    def estimate_betas(self, traces_prof, x_prof, k_b, start_time, end_time):\n",
    "        phi_prof = np.bitwise_xor(x_prof, k_b) & 0x0F\n",
    "        G_prof = self.basis_functions.G[phi_prof]  # shape (N1, num_basis)\n",
    "        I = traces_prof[:, start_time:end_time]  # shape (N1, segment_length)\n",
    "        G_pinv = pinv(G_prof)\n",
    "        betas = G_pinv @ I    # Shape (num_basis, segment_length)\n",
    "        self.betas = betas.T  # Match old shape (segment_length, num_basis)\n",
    "        self.start_time = start_time\n",
    "        return self.betas\n",
    "\n",
    "    def select_time_points(self,betas, tau, selection_mode='S2', traces_prof=None):\n",
    "        \"\"\"Selects relevant time points ts based on the norm of data-dependent betas.\"\"\"\n",
    "        norm_b = np.linalg.norm(betas[:, 1:], axis=1)  # Exclude constant term\n",
    "        if selection_mode == 'S3':\n",
    "            self.ts = [np.argmax(norm_b)]  #Single max peak\n",
    "        elif selection_mode == 'S2':\n",
    "            self.ts = [int(x) for x in np.argsort(norm_b)[-5:]]  # Top 10 peaks\n",
    "        elif selection_mode == 'S6':\n",
    "            self.ts = np.argsort(norm_b)[-21:]  #Top 21 peaks\n",
    "        elif selection_mode == 'S1':\n",
    "            self.ts = np.where(norm_b >= tau)[0]  #Threshold-based\n",
    "        elif selection_mode in ['S4', 'S5']:\n",
    "            if traces_prof is None:\n",
    "                raise ValueError(\"traces_prof required for S4/S5 selection modes\")\n",
    "            var_t = np.var(traces_prof, axis=0)\n",
    "            mask = (norm_b >= tau) & (norm_b > var_t)\n",
    "            self.ts = np.where(mask)[0]\n",
    "            if selection_mode == 'S5':\n",
    "                extra_mask = (norm_b >= tau / 2) & ~mask\n",
    "                self.ts = np.concatenate((self.ts, np.where(extra_mask)[0]))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown selection_mode: {selection_mode}\")\n",
    "        return self.ts\n",
    "    \n",
    "    def detect_noise(self, traces_prof, x_prof, k_b):\n",
    "        \"\"\"Detect noise levels using residuals after beta fitting.\"\"\"\n",
    "        if self.betas is None:\n",
    "            raise ValueError(\"Run estimate_betas first\")\n",
    "        \n",
    "        # Compute predicted h_t for all t in segment\n",
    "        phi_prof = np.bitwise_xor(x_prof, k_b) & 0x0F\n",
    "        G_prof = self.basis_functions.G[phi_prof]  # N1 x 5\n",
    "        h_pred = np.dot(G_prof, self.betas.T)  # N1 x segment_length\n",
    "        # Residuals = observed - predicted\n",
    "        segment_traces = traces_prof[:, self.start_time:self.start_time + len(self.betas)]\n",
    "        residuals = segment_traces - h_pred\n",
    "        # Noise metrics\n",
    "        noise_var = np.var(residuals)  # Overall var(R_t)\n",
    "        signal_var = np.var(h_pred)    # var(h_t)\n",
    "        snr = signal_var / noise_var if noise_var > 0 else float('inf')\n",
    "        # Per-time variance\n",
    "        noise_var_per_t = np.var(residuals, axis=0)  # segment_length x 1\n",
    "        return snr, noise_var, noise_var_per_t\n",
    "\n",
    "\n",
    "class KeyExtraction:\n",
    "    \"\"\"Handles key extraction using minimum or maximum likelihood principles.\"\"\"\n",
    "    def __init__(self, profiling):\n",
    "        self.profiling = profiling\n",
    "        self.basis_functions = profiling.basis_functions\n",
    "        self.betas = profiling.betas\n",
    "        self.ts = profiling.ts\n",
    "        self.cov = profiling.cov\n",
    "\n",
    "    def extract_key(self, traces_attack, x_attack,betas, ts,  N3, method='minimum'):\n",
    "        \"\"\"Extracts the subkey using the specified method.\"\"\"\n",
    "        extracted_key = {i: 0 for i in range(16)}\n",
    "        G = self.basis_functions.G\n",
    "        betas_ts = betas[ts]\n",
    "        if method == 'minimum':\n",
    "            min_diff = float('inf')\n",
    "            best_k = None\n",
    "            for k_prime in range(16):\n",
    "                diff = 0.0\n",
    "                for j in range(N3):\n",
    "                    phi_j = np.bitwise_xor(x_attack[j], k_prime) & 0x0F\n",
    "                    h_j = betas_ts @ G[phi_j]\n",
    "                    i_j = traces_attack[j, ts]\n",
    "                    diff += np.sum((i_j - h_j) ** 2)\n",
    "                avg_diff = diff / N3\n",
    "                if avg_diff < min_diff:\n",
    "                    min_diff = avg_diff\n",
    "                    best_k = k_prime\n",
    "                    extracted_key[k_prime] = extracted_key[k_prime]+1\n",
    "            return best_k, extracted_key\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "\n",
    "    def compute_success_rate(self, traces_attack, x_attack,betas,timepoints, correct_k, sampled=50, num_trials=10, method='minimum'):\n",
    "        \"\"\"Computes the success rate over multiple trials with random subsets.\"\"\"\n",
    "        num_attack = len(x_attack)\n",
    "        success = 0\n",
    "        for _ in range(num_trials):\n",
    "            indices = random.sample(range(num_attack), sampled)\n",
    "            traces_sub = traces_attack[indices]\n",
    "            x_sub = x_attack[indices]\n",
    "            extracted_k = self.extract_key(traces_sub, x_sub,betas, timepoints, sampled, method)\n",
    "            if extracted_k == correct_k:\n",
    "                success += 1\n",
    "        return (success / num_trials) * 100\n",
    "    \n",
    "def create_range(start_time=0, end_time=5000, increments=(5, 10), widths=(10, 20)):\n",
    "    ranges = set()\n",
    "    widths = tuple(sorted(widths))\n",
    "    min_w = widths[0]\n",
    "\n",
    "    for inc in increments:\n",
    "        s = start_time\n",
    "        while s + min_w <= end_time:\n",
    "            for w in widths:\n",
    "                end = s + w\n",
    "                if end > end_time:\n",
    "                    break\n",
    "                ranges.add((s, end))\n",
    "            s += inc\n",
    "    return sorted(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64b071d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted key =  15 {0: 1, 2: 1, 3: 1, 15: 1} correct key =  15\n",
      "Extracted key =  14 {0: 1, 3: 1, 14: 1} correct key =  14\n",
      "Extracted key =  14 {0: 1, 1: 1, 2: 1, 6: 1, 13: 1, 14: 1} correct key =  13\n",
      "Extracted key =  12 {0: 1, 12: 1} correct key =  12\n",
      "Extracted key =  11 {0: 1, 1: 1, 7: 1, 8: 1, 11: 1} correct key =  11\n",
      "Extracted key =  10 {0: 1, 1: 1, 6: 1, 10: 1} correct key =  10\n",
      "Extracted key =  9 {0: 1, 3: 1, 9: 1} correct key =  9\n",
      "Extracted key =  8 {0: 1, 1: 1, 2: 1, 8: 1} correct key =  8\n",
      "Extracted key =  7 {0: 1, 4: 1, 6: 1, 7: 1} correct key =  7\n",
      "Extracted key =  6 {0: 1, 4: 1, 5: 1, 6: 1} correct key =  6\n",
      "Extracted key =  5 {0: 1, 1: 1, 2: 1, 4: 1, 5: 1} correct key =  5\n",
      "Extracted key =  4 {0: 1, 3: 1, 4: 1} correct key =  4\n",
      "Extracted key =  3 {0: 1, 2: 1, 3: 1} correct key =  3\n",
      "Extracted key =  2 {0: 1, 1: 1, 2: 1} correct key =  2\n",
      "Extracted key =  1 {0: 1, 1: 1} correct key =  1\n",
      "Extracted key =  0 {0: 1} correct key =  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Total correct bytes: 16/16'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import SDSCA as sd\n",
    "total_prof = 20000\n",
    "key = np.array([15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0], dtype=np.uint8)\n",
    "ATTACK_START = 25000\n",
    "ATTACK_END = 30000\n",
    "TOTAL_ATTACK = ATTACK_END - ATTACK_START\n",
    "PROF_START = 0\n",
    "PROF_END = 5000\n",
    "correct_count = 0\n",
    "for byte_idx in range(16):\n",
    "    plaintexts_all = random_plaintexts[:, byte_idx] & 0x0F  # Lower 4 bits\n",
    "    k_b = key[byte_idx] & 0x0F\n",
    "    traces_prof = scaled_traces[:total_prof]\n",
    "    plaintexts_prof = plaintexts_all[:total_prof]\n",
    "    AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA,0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "    bf = BasisFunctions(AES_SBOX, basis_type=\"hw\")\n",
    "    prof = Profiling(bf)\n",
    "    betas = prof.estimate_betas(traces_prof, plaintexts_prof, k_b,PROF_START, PROF_END)\n",
    "    timepoints = prof.select_time_points(betas, 0.1, selection_mode=\"S2\")\n",
    "    traces_attack = scaled_traces[ATTACK_START:ATTACK_END]\n",
    "    plaintexts_attack = plaintexts_all[ATTACK_START:ATTACK_END]\n",
    "    ke = KeyExtraction(prof)\n",
    "    extracted_k, exp_keys = ke.extract_key(traces_attack, plaintexts_attack, betas, timepoints, TOTAL_ATTACK, method=\"minimum\")\n",
    "    filtered = {k: v for k, v in exp_keys.items() if v}\n",
    "    if key[byte_idx] in filtered.keys():\n",
    "        correct_count += 1\n",
    "    print(\"Extracted key = \", extracted_k,filtered, \"correct key = \", key[byte_idx])\n",
    "f\"Total correct bytes: {correct_count}/{16}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3fbc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
