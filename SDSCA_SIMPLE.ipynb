{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4fb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy pandas scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e96593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "type_converter = {i: lambda x: int(x, 16) for i in range(16)}\n",
    "LAB_PATH = \"/scratch/net4/HOS/Traces\"\n",
    "ATTACK_PATH = \"/home/navanerj/Downloads/ATTACK\"\n",
    "MAX_ROWS = 30000 #Total Number of rows to be selected\n",
    "ROUND1_START = 20000\n",
    "ROUND1_END = 25000\n",
    "SCALE = 3\n",
    "m_off = 0\n",
    "AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA,0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "random_plaintexts = np.loadtxt(os.path.join(LAB_PATH,\"plaintexts.txt\"), dtype=np.uint8, max_rows=MAX_ROWS, converters=type_converter)\n",
    "random_ciphertexts = np.loadtxt(os.path.join(LAB_PATH,\"ciphertexts.txt\"), dtype=np.uint8, max_rows=MAX_ROWS, converters=type_converter)\n",
    "random_traces = np.loadtxt(os.path.join(LAB_PATH,\"traces.txt\"), max_rows=MAX_ROWS)\n",
    "unscaled_traces = random_traces[:,ROUND1_START:ROUND1_END]\n",
    "\n",
    "scaled_traces = ((unscaled_traces / 127) * 4) * SCALE + m_off\n",
    "\n",
    "print(\"unscaled traces shape: \", unscaled_traces.shape)\n",
    "print(\"scaled traces shape: \", scaled_traces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c848152",
   "metadata": {},
   "source": [
    "## Stochastic Model for DSCA \n",
    "- Constructing Basis functions\n",
    "- Profiling based on SBOX output of 1st round\n",
    "- Key Extraction based on minimum residual error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce104c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq, pinv\n",
    "import random\n",
    "from numpy import linalg\n",
    "\n",
    "class BasisFunctions:\n",
    "    \"\"\"Handles the precomputation of the basis matrix G for a 4-bit S-Box.\"\"\"\n",
    "    def __init__(self, sbox, basis_type='bits'):\n",
    "        self.sbox = sbox\n",
    "        if basis_type in [\"hw\", \"lsb\"]:\n",
    "            self.num_basis = 2\n",
    "        else:\n",
    "            self.num_basis = 5\n",
    "        self.basis_type = basis_type\n",
    "        self.G = self._build_basis_matrix()\n",
    "\n",
    "    def _build_basis_matrix(self):\n",
    "        \"\"\"Precomputes the basis matrix G for all phi values (0-15) based on actual bit value and HW\"\"\"\n",
    "        G = np.zeros((16, self.num_basis), dtype=float)\n",
    "        for phi in range(16):\n",
    "            sbox_output = self.sbox[phi]\n",
    "            if(self.basis_type == 'bits'):\n",
    "                G[phi] = [1.0]+[float(i) for i in format(sbox_output, '04b')]\n",
    "            elif(self.basis_type == 'hw_bits'):\n",
    "                G[phi] = [1.0] + [float(i) for i in format(bin(sbox_output).count('1'),'04b')]\n",
    "            elif(self.basis_type == 'hw'):\n",
    "                G[phi] = [1.0] + [float(bin(sbox_output).count('1'))]\n",
    "            elif(self.basis_type == 'lsb'):\n",
    "                G[phi] = [1.0, float(sbox_output & 1)]\n",
    "        return G\n",
    "\n",
    "class Profiling:\n",
    "    \"\"\"Manages the profiling phase: beta estimation, time point selection, and covariance estimation.\"\"\"\n",
    "    def __init__(self, basis_functions):\n",
    "        self.basis_functions = basis_functions\n",
    "        self.betas = None\n",
    "        self.ts = None\n",
    "        self.cov = None\n",
    "\n",
    "    def estimate_betas(self, traces_prof, x_prof, k_b, start_time, end_time):\n",
    "        phi_prof = np.bitwise_xor(x_prof, k_b) & 0x0F\n",
    "        G_prof = self.basis_functions.G[phi_prof]  # shape (N1, num_basis)\n",
    "        I = traces_prof[:, start_time:end_time]  # shape (N1, segment_length)\n",
    "        G_pinv = pinv(G_prof)\n",
    "        betas = G_pinv @ I    # Shape (num_basis, segment_length)\n",
    "        self.betas = betas.T  # Match old shape (segment_length, num_basis)\n",
    "        self.start_time = start_time\n",
    "        return self.betas\n",
    "\n",
    "    def select_time_points(self,betas, tau,N = 15, selection_mode='S2', traces_prof=None):\n",
    "        \"\"\"Selects relevant time points ts based on the norm of data-dependent betas.\"\"\"\n",
    "        norm_b = np.linalg.norm(betas[:, 1:], axis=1)  # Exclude constant term\n",
    "        if selection_mode == 'S3':\n",
    "            self.ts = [np.argmax(norm_b)]  #Single max peak\n",
    "        elif selection_mode == 'S2':\n",
    "            self.ts = [int(x) for x in np.argsort(norm_b)[-N:]]  # Top N peaks\n",
    "        elif selection_mode == 'S1':\n",
    "            self.ts = np.where(norm_b >= tau)[0]  #Threshold-based\n",
    "        elif selection_mode in ['S4', 'S5']:\n",
    "            if traces_prof is None:\n",
    "                raise ValueError(\"traces_prof required for S4/S5 selection modes\")\n",
    "            var_t = np.var(traces_prof, axis=0)\n",
    "            mask = (norm_b >= tau) & (norm_b > var_t)\n",
    "            self.ts = np.where(mask)[0]\n",
    "            if selection_mode == 'S5':\n",
    "                extra_mask = (norm_b >= tau / 2) & ~mask\n",
    "                self.ts = np.concatenate((self.ts, np.where(extra_mask)[0]))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown selection_mode: {selection_mode}\")\n",
    "        return self.ts\n",
    "    \n",
    "    def estimate_covariance(self, traces_noise, x_noise, k_b):\n",
    "        \"\"\"Estimates the covariance matrix of residuals for ML key extraction.\"\"\"\n",
    "        N2 = len(x_noise)\n",
    "        m = len(self.ts)\n",
    "        phi_noise = np.bitwise_xor(x_noise, k_b) & 0x0F\n",
    "        G_phi = self.basis_functions.G[phi_noise]  # [N2, 5]\n",
    "        betas_ts = self.betas[self.ts]  # [m, 5]\n",
    "        h_star_all = np.einsum('ij,kj->ik', G_phi, betas_ts)  # [N2, m]\n",
    "        residuals = traces_noise[:, self.ts] - h_star_all\n",
    "        self.cov = np.cov(residuals.T)\n",
    "\n",
    "class KeyExtraction:\n",
    "    \"\"\"Handles key extraction using minimum or maximum likelihood principles.\"\"\"\n",
    "    def __init__(self, profiling):\n",
    "        self.profiling = profiling\n",
    "        self.basis_functions = profiling.basis_functions\n",
    "        self.betas = profiling.betas\n",
    "        self.ts = profiling.ts\n",
    "        self.cov = profiling.cov\n",
    "\n",
    "    def extract_key(self, traces_attack, x_attack,betas, ts,  N3, method='minimum'):\n",
    "        \"\"\"Extracts the subkey using the specified method.\"\"\"\n",
    "        extracted_key = {i: 0 for i in range(16)}\n",
    "        num_candidates = 16\n",
    "        key_scores = np.zeros(num_candidates)\n",
    "        G = self.basis_functions.G\n",
    "        betas_ts = betas[ts]\n",
    "        if method == 'minimum':\n",
    "            min_diff = float('inf')\n",
    "            best_k = None\n",
    "            for k_prime in range(num_candidates):\n",
    "                diff = 0.0\n",
    "                for j in range(N3):\n",
    "                    phi_j = np.bitwise_xor(x_attack[j], k_prime) & 0x0F\n",
    "                    h_j = betas_ts @ G[phi_j]\n",
    "                    i_j = traces_attack[j, ts]\n",
    "                    diff += np.sum((i_j - h_j) ** 2)\n",
    "                avg_diff = diff / N3\n",
    "                if avg_diff < min_diff:\n",
    "                    min_diff = avg_diff\n",
    "                    best_k = k_prime\n",
    "                    extracted_key[k_prime] = extracted_key[best_k] + 1\n",
    "            return best_k, extracted_key\n",
    "        \n",
    "        elif method == 'maximum':\n",
    "            if self.cov is None:\n",
    "                raise ValueError(\"Covariance matrix not available. Estimate it in profiling first.\")\n",
    "\n",
    "            # Precompute covariance inverse and determinant for Gaussian PDF\n",
    "            try:\n",
    "                C_inv = np.linalg.inv(self.cov)\n",
    "            except np.linalg.LinAlgError:\n",
    "                C_inv = np.linalg.pinv(self.cov)\n",
    "            best_k = None\n",
    "            for k_prime in range(num_candidates):\n",
    "                val = 0.0\n",
    "                for j in range(N3):\n",
    "                    phi_j = np.bitwise_xor(x_attack[j], k_prime) & 0x0F\n",
    "                    h_j = betas_ts @ G[phi_j]     # Predicted deterministic leakage\n",
    "                    i_j = traces_attack[j, ts]    # Measured leakage\n",
    "                    delta = i_j - h_j             # Residual noise vector\n",
    "                    val += delta.T @ C_inv @ delta\n",
    "                key_scores[k_prime] = val\n",
    "\n",
    "            top_k_indices = np.argsort(key_scores)[:5]\n",
    "            top_k_scores = key_scores[top_k_indices]\n",
    "            top_candidates = {int(k): float(s) for k, s in zip(top_k_indices, top_k_scores)}\n",
    "            return int(top_k_indices[0]), top_candidates\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "def create_range(start_time=0, end_time=5000, increments=(5, 10), widths=(10, 20)):\n",
    "    ranges = set()\n",
    "    widths = tuple(sorted(widths))\n",
    "    min_w = widths[0]\n",
    "\n",
    "    for inc in increments:\n",
    "        s = start_time\n",
    "        while s + min_w <= end_time:\n",
    "            for w in widths:\n",
    "                end = s + w\n",
    "                if end > end_time:\n",
    "                    break\n",
    "                ranges.add((s, end))\n",
    "            s += inc\n",
    "    return sorted(ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5394e6fb",
   "metadata": {},
   "source": [
    "## Profiling and Key Extraction using Known Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64b071d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Success Rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# import SDSCA as sd\n",
    "total_prof = 10000\n",
    "key = np.array([15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0], dtype=np.uint8)\n",
    "ATTACK_START = 20000\n",
    "ATTACK_END = 23000\n",
    "TOTAL_ATTACK = ATTACK_END - ATTACK_START\n",
    "PROF_START = 0\n",
    "PROF_END = 5000\n",
    "correct_count = 0\n",
    "top_n = 4\n",
    "results = []\n",
    "METHOD = \"maximum\"\n",
    "N_POINTS = 20\n",
    "N2 = 1000\n",
    "BASIS_TYPE = \"hw\"\n",
    "for byte_idx in range(16):\n",
    "    plaintexts_all = random_plaintexts[:, byte_idx] & 0x0F  # Lower 4 bits\n",
    "    k_b = key[byte_idx] & 0x0F\n",
    "    traces_prof = scaled_traces[:total_prof]\n",
    "    plaintexts_prof = plaintexts_all[:total_prof]\n",
    "    AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA,0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "    bf = BasisFunctions(AES_SBOX, basis_type=BASIS_TYPE)\n",
    "    prof = Profiling(bf)\n",
    "    betas = prof.estimate_betas(traces_prof, plaintexts_prof, k_b,PROF_START, PROF_END)\n",
    "    timepoints = prof.select_time_points(betas, 0.1,N=N_POINTS,  selection_mode=\"S2\")\n",
    "    traces_attack = scaled_traces[ATTACK_START:ATTACK_END]\n",
    "    plaintexts_attack = plaintexts_all[ATTACK_START:ATTACK_END]\n",
    "\n",
    "    if METHOD == \"maximum\":\n",
    "        traces_prof = scaled_traces[total_prof:total_prof+N2]\n",
    "        plaintexts_prof = plaintexts_all[total_prof:total_prof+N2]\n",
    "        prof.estimate_covariance(traces_prof, plaintexts_prof, k_b)\n",
    "    ke = KeyExtraction(prof)\n",
    "    extracted_k, exp_keys = ke.extract_key(traces_attack, plaintexts_attack, betas, timepoints, TOTAL_ATTACK, method=METHOD)\n",
    "    filtered = {k: v for k, v in exp_keys.items() if v}\n",
    "    if key[byte_idx] in filtered.keys():\n",
    "        correct_count += 1\n",
    "    sorted_candidates = sorted(filtered.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_candidates = [int(k) for k, _ in sorted_candidates]\n",
    "\n",
    "    correct_key = int(key[byte_idx])\n",
    "    if correct_key==extracted_k:\n",
    "        success = True\n",
    "        correct_count += 1\n",
    "    else:\n",
    "        success = any((cand is not None and int(cand) == int(correct_key)) for cand in top_candidates)\n",
    "\n",
    "    row = {\n",
    "        \"byte\": byte_idx,\n",
    "        \"correct_key\": correct_key,\n",
    "        \"extracted_key\": int(extracted_k),\n",
    "        \"candidates\": top_candidates,\n",
    "        \"success\": success\n",
    "    }\n",
    "    results.append(row)\n",
    "\n",
    "df_attack = pd.DataFrame(results,\n",
    "                         columns=[\"byte\", \"correct_key\", \"extracted_key\",\n",
    "                                  \"candidates\",\"success\"])\n",
    "\n",
    "success_rate = (int(df_attack['success'].sum()) / 16) * 100\n",
    "print(f\"Overall Success Rate: {success_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d14c21",
   "metadata": {},
   "source": [
    "# Known Key Attack using all possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "ATTACK_START = 20000\n",
    "ATTACK_END_LIST = [21000, 22000, 23000, 24000, 25000]\n",
    "METHOD_LIST = [\"minimum\", \"maximum\"]\n",
    "N_POINTS_LIST = [5, 10, 15, 20]\n",
    "BASIS_TYPE_LIST = [\"hw_bits\", \"hw\"]\n",
    "TOTAL_PROF_LIST = [5000, 10000]\n",
    "key = np.array([15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0], dtype=np.uint8)\n",
    "PROF_START = 0\n",
    "PROF_END = 5000\n",
    "N2 = 1000\n",
    "\n",
    "AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA,\n",
    "            0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for ATTACK_END, METHOD, N_POINTS, BASIS_TYPE, TOTAL_PROF in itertools.product(\n",
    "        ATTACK_END_LIST, METHOD_LIST, N_POINTS_LIST, BASIS_TYPE_LIST, TOTAL_PROF_LIST):\n",
    "    \n",
    "    TOTAL_ATTACK = ATTACK_END - ATTACK_START\n",
    "    results = []\n",
    "    correct_count = 0\n",
    "\n",
    "    # Lists for timing per byte\n",
    "    prof_times_per_byte = []\n",
    "    attack_times_per_byte = []\n",
    "\n",
    "    for byte_idx in range(16):\n",
    "        plaintexts_all = random_plaintexts[:, byte_idx] & 0x0F  # Lower 4 bits\n",
    "        k_b = key[byte_idx] & 0x0F\n",
    "        traces_prof = scaled_traces[:TOTAL_PROF]\n",
    "        plaintexts_prof = plaintexts_all[:TOTAL_PROF]\n",
    "\n",
    "        bf = BasisFunctions(AES_SBOX, basis_type=BASIS_TYPE)\n",
    "        prof = Profiling(bf)\n",
    "\n",
    "        # --- Profiling timing (includes estimate_betas, select_time_points, and covariance if used) ---\n",
    "        t_prof_start = time.perf_counter()\n",
    "        betas = prof.estimate_betas(traces_prof, plaintexts_prof, k_b, PROF_START, PROF_END)\n",
    "        timepoints = prof.select_time_points(betas, 0.1, N=N_POINTS, selection_mode=\"S2\")\n",
    "\n",
    "        if METHOD == \"maximum\":\n",
    "            # estimate_covariance is considered part of profiling\n",
    "            traces_prof_ = scaled_traces[TOTAL_PROF:TOTAL_PROF+N2]\n",
    "            plaintexts_prof_ = plaintexts_all[TOTAL_PROF:TOTAL_PROF+N2]\n",
    "            prof.estimate_covariance(traces_prof_, plaintexts_prof_, k_b)\n",
    "\n",
    "        t_prof_end = time.perf_counter()\n",
    "        prof_time = t_prof_end - t_prof_start\n",
    "        prof_times_per_byte.append(prof_time)\n",
    "\n",
    "        # Prepare attack data\n",
    "        traces_attack = scaled_traces[ATTACK_START:ATTACK_END]\n",
    "        plaintexts_attack = plaintexts_all[ATTACK_START:ATTACK_END]\n",
    "\n",
    "        # --- Attack timing (key extraction) ---\n",
    "        ke = KeyExtraction(prof)\n",
    "        t_attack_start = time.perf_counter()\n",
    "        extracted_k, exp_keys = ke.extract_key(\n",
    "            traces_attack, plaintexts_attack, betas, timepoints, TOTAL_ATTACK, method=METHOD\n",
    "        )\n",
    "        t_attack_end = time.perf_counter()\n",
    "        attack_time = t_attack_end - t_attack_start\n",
    "        attack_times_per_byte.append(attack_time)\n",
    "\n",
    "        filtered = {k: v for k, v in exp_keys.items() if v}\n",
    "        sorted_candidates = sorted(filtered.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_candidates = [int(k) for k, _ in sorted_candidates]\n",
    "        correct_key = int(key[byte_idx])\n",
    "        success = (correct_key == int(extracted_k)) or \\\n",
    "                  any((cand is not None and int(cand) == correct_key) for cand in top_candidates)\n",
    "\n",
    "        results.append(success)\n",
    "\n",
    "    success_rate = (sum(results) / 16) * 100\n",
    "\n",
    "    # average times across 16 bytes for this parameter combination\n",
    "    avg_prof_time = float(np.mean(prof_times_per_byte)) if prof_times_per_byte else 0.0\n",
    "    avg_attack_time = float(np.mean(attack_times_per_byte)) if attack_times_per_byte else 0.0\n",
    "\n",
    "    all_results.append({\n",
    "        \"ATTACK_END\": ATTACK_END,\n",
    "        \"METHOD\": METHOD,\n",
    "        \"N_POINTS\": N_POINTS,\n",
    "        \"BASIS_TYPE\": BASIS_TYPE,\n",
    "        \"Success_Rate(%)\": round(success_rate, 2),\n",
    "        \"Avg_Profiling_Time_s\": round(avg_prof_time, 6),\n",
    "        \"Avg_Attack_Time_s\": round(avg_attack_time, 6)\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(all_results)\n",
    "\n",
    "# Print DataFrame\n",
    "# sprint(df_summary.to_string(index=False))\n",
    "\n",
    "# Print overall averages across ALL parameter combinations\n",
    "overall_avg_prof = df_summary[\"Avg_Profiling_Time_s\"].mean()\n",
    "overall_avg_attack = df_summary[\"Avg_Attack_Time_s\"].mean()\n",
    "print(\"\\nOverall averages across all parameter combinations:\")\n",
    "print(f\"  Average profiling time per byte (s): {overall_avg_prof:.6f}\")\n",
    "print(f\"  Average attack time per byte (s):    {overall_avg_attack:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c51841",
   "metadata": {},
   "source": [
    "## Profiling and Key Extraction using Unknown Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81ecd9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bytes: 100%|██████████| 16/16 [07:02<00:00, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20000 10000 hw_bits 10 maximum\n",
      "Key recovery incomplete: 9/16 bytes matched one of the top-4 candidates.\n",
      "\n",
      "===== Timing Summary =====\n",
      "Total profiling time: 38.737 s\n",
      "Total attack time:    383.549 s\n",
      "Average profiling time per candidate: 0.1513 s\n",
      "Average attack time per candidate:    1.4982 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "total_prof = 20000  # N1\n",
    "N2 = 5000\n",
    "ATTACK_START = 20000\n",
    "ATTACK_END = 30000\n",
    "TOTAL_ATTACK = ATTACK_END - ATTACK_START\n",
    "PROF_START = 0\n",
    "PROF_END = 5000\n",
    "METHOD = \"maximum\"\n",
    "N_POINTS = 10\n",
    "BASIS_TYPE = \"hw_bits\"\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    use_tqdm = True\n",
    "except Exception:\n",
    "    use_tqdm = False\n",
    "\n",
    "byte_iter = range(16)\n",
    "if use_tqdm:\n",
    "    byte_iter = tqdm(byte_iter, desc=\"bytes\")\n",
    "\n",
    "top_n = 5\n",
    "AES_SBOX = [0x6, 0xB, 0x5, 0x4, 0x2, 0xE, 0x7, 0xA, 0x9, 0xD, 0xF, 0xC, 0x3, 0x1, 0x0, 0x8]\n",
    "key = np.array([15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0], dtype=np.uint8)\n",
    "\n",
    "best_candidates_per_byte = {}\n",
    "candidate_range = range(16)\n",
    "bf = BasisFunctions(AES_SBOX, basis_type=BASIS_TYPE)\n",
    "prof = Profiling(bf)\n",
    "\n",
    "# Timing accumulators\n",
    "total_profiling_time = 0.0\n",
    "total_attack_time = 0.0\n",
    "\n",
    "for byte_idx in byte_iter:\n",
    "    plaintexts_all = random_plaintexts[:, byte_idx] & 0x0F\n",
    "    traces_prof = scaled_traces[:total_prof]\n",
    "    plaintexts_prof = plaintexts_all[:total_prof]\n",
    "    candidate_scores = []\n",
    "\n",
    "    for cand in candidate_range:\n",
    "        k_b = int(cand & 0x0F)\n",
    "\n",
    "        # --- Profiling timing ---\n",
    "        t_prof_start = time.perf_counter()\n",
    "        try:\n",
    "            betas = prof.estimate_betas(traces_prof, plaintexts_prof, k_b, PROF_START, PROF_END)\n",
    "            timepoints = prof.select_time_points(betas, 0.1, N=N_POINTS, selection_mode=\"S2\")\n",
    "\n",
    "            if METHOD == \"maximum\":\n",
    "                traces_prof_ = scaled_traces[total_prof:total_prof+N2]\n",
    "                plaintexts_prof_ = plaintexts_all[total_prof:total_prof+N2]\n",
    "                prof.estimate_covariance(traces_prof_, plaintexts_prof_, k_b)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[byte {byte_idx} cand {cand}] profiling failed: {e}\")\n",
    "            continue\n",
    "        t_prof_end = time.perf_counter()\n",
    "        total_profiling_time += (t_prof_end - t_prof_start)\n",
    "\n",
    "        # --- Attack timing ---\n",
    "        traces_attack = scaled_traces[ATTACK_START:ATTACK_END]\n",
    "        plaintexts_attack = plaintexts_all[ATTACK_START:ATTACK_END]\n",
    "        ke = KeyExtraction(prof)\n",
    "\n",
    "        t_attack_start = time.perf_counter()\n",
    "        try:\n",
    "            extracted_k, exp_keys = ke.extract_key(\n",
    "                traces_attack, plaintexts_attack, betas, timepoints, TOTAL_ATTACK, method=METHOD\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[byte {byte_idx} cand {cand}] extract_key failed: {e}\")\n",
    "            continue\n",
    "        t_attack_end = time.perf_counter()\n",
    "        total_attack_time += (t_attack_end - t_attack_start)\n",
    "\n",
    "        # --- Scoring ---\n",
    "        score = 0.0\n",
    "        try:\n",
    "            if isinstance(exp_keys, dict):\n",
    "                score = float(exp_keys.get(cand, 0))\n",
    "            else:\n",
    "                score = 1.0 if extracted_k == cand else 0.0\n",
    "        except Exception:\n",
    "            score = 0.0\n",
    "\n",
    "        if extracted_k == cand:\n",
    "            score += 10.0\n",
    "\n",
    "        try:\n",
    "            exp_keys_snapshot = dict(exp_keys) if isinstance(exp_keys, dict) else {\"value\": exp_keys}\n",
    "        except Exception:\n",
    "            exp_keys_snapshot = {\"unserializable\": str(type(exp_keys))}\n",
    "\n",
    "        candidate_scores.append((cand, score, extracted_k, exp_keys_snapshot))\n",
    "\n",
    "    # Sort and store top candidates\n",
    "    candidate_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    best_candidates_per_byte[byte_idx] = candidate_scores[:top_n]\n",
    "\n",
    "# --- Result Summary ---\n",
    "top_k = 4\n",
    "csv_filename = \"byte_top4_separate_cols.csv\"\n",
    "all_success = True\n",
    "success_count = 0\n",
    "result_rows = []\n",
    "\n",
    "for b in range(16):\n",
    "    try:\n",
    "        correct_key = int(key[b])\n",
    "    except Exception:\n",
    "        correct_key = None\n",
    "\n",
    "    cand_list = best_candidates_per_byte.get(b, [])\n",
    "    top_candidates = [int(t[0]) for t in cand_list[:top_k]]\n",
    "    if len(top_candidates) < top_k:\n",
    "        top_candidates += [None] * (top_k - len(top_candidates))\n",
    "\n",
    "    if correct_key is None:\n",
    "        success = False\n",
    "    else:\n",
    "        success = any((cand is not None and int(cand) == int(correct_key)) for cand in top_candidates)\n",
    "\n",
    "    if success:\n",
    "        success_count += 1\n",
    "    else:\n",
    "        all_success = False\n",
    "\n",
    "    row = {\n",
    "        \"byte\": b,\n",
    "        \"correct_key\": correct_key,\n",
    "        \"cand_1\": top_candidates[0],\n",
    "        \"cand_2\": top_candidates[1],\n",
    "        \"cand_3\": top_candidates[2],\n",
    "        \"cand_4\": top_candidates[3],\n",
    "        \"success\": success\n",
    "    }\n",
    "    result_rows.append(row)\n",
    "\n",
    "df_top4 = pd.DataFrame(result_rows)\n",
    "print(f\"\\n{total_prof} {TOTAL_ATTACK} {BASIS_TYPE} {N_POINTS} {METHOD}\")\n",
    "\n",
    "if all_success and success_count == 16:\n",
    "    print(\"Key recovered successfully ✅\")\n",
    "else:\n",
    "    print(f\"Key recovery incomplete: {success_count}/16 bytes matched one of the top-{top_k} candidates.\")\n",
    "\n",
    "# --- Timing Summary ---\n",
    "print(\"\\n===== Timing Summary =====\")\n",
    "print(f\"Total profiling time: {total_profiling_time:.3f} s\")\n",
    "print(f\"Total attack time:    {total_attack_time:.3f} s\")\n",
    "print(f\"Average profiling time per candidate: {total_profiling_time/(16*len(candidate_range)):.4f} s\")\n",
    "print(f\"Average attack time per candidate:    {total_attack_time/(16*len(candidate_range)):.4f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef5b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
